{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top Trending Coin on Reddit**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "praw – Interacts with Reddit’s API to fetch posts and comments. logging – Tracks errors, warnings, and events for debugging. dotenv – Loads API keys securely from a .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (7.8.1)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.0.1)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update_checker>=0.18 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nihal/Library/Python/3.13/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nihal/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install praw pandas requests python-dotenv\n",
    "import praw\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Fetches and filters cryptocurrencies listed on **both CoinGecko and Coinbase**:\n",
    "- **APIs Used**:  \n",
    "  CoinGecko (`/coins/list`) for symbols/names, Coinbase (`/products`) for trading pairs.\n",
    "- **Filters**:  \n",
    "  - Keeps cryptos present in **both platforms** (symbols from CoinGecko, product IDs from Coinbase).  \n",
    "  - Explicitly removes **BTC** and **ETH** (and their names).  \n",
    "- **Returns**:  \n",
    "  - `verified_crypto_set`: Lowercase symbols (e.g., `sol`, `ada`).  \n",
    "  - `verified_crypto_names`: Names (likely empty due to symbol/name mismatch).  \n",
    "\n",
    "Handles API errors and logs status.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging setup\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(message)s\"\n",
    ")\n",
    "\n",
    "def get_verified_crypto_list():\n",
    "    \"\"\"Fetch a list of real cryptocurrencies from CoinGecko and Coinbase, filtering by market cap.\"\"\"\n",
    "    coingecko_url = \"https://api.coingecko.com/api/v3/coins/list\"\n",
    "    coinbase_url = \"https://api.exchange.coinbase.com/products\"\n",
    "    \n",
    "    try:\n",
    "        response_gecko = requests.get(coingecko_url)\n",
    "        response_coinbase = requests.get(coinbase_url)\n",
    "        \n",
    "        if response_gecko.status_code == 200 and response_coinbase.status_code == 200:\n",
    "            coin_data_gecko = response_gecko.json()\n",
    "            coin_data_coinbase = response_coinbase.json()\n",
    "            \n",
    "            crypto_set_gecko = {coin[\"symbol\"].lower() for coin in coin_data_gecko}\n",
    "            crypto_names_gecko = {coin[\"name\"].lower() for coin in coin_data_gecko}\n",
    "            \n",
    "            crypto_set_coinbase = {product[\"id\"].split('-')[0].lower() for product in coin_data_coinbase}\n",
    "            \n",
    "            verified_crypto_set = crypto_set_gecko.intersection(crypto_set_coinbase)\n",
    "            verified_crypto_names = crypto_names_gecko.intersection(crypto_set_coinbase)\n",
    "            \n",
    "            verified_crypto_set.discard('btc')\n",
    "            verified_crypto_set.discard('eth')\n",
    "            verified_crypto_names.discard('bitcoin')\n",
    "            verified_crypto_names.discard('ethereum')\n",
    "            \n",
    "            logging.info(f\"Loaded {len(verified_crypto_set)} verified cryptocurrencies from CoinGecko and Coinbase.\")\n",
    "            return verified_crypto_set, verified_crypto_names\n",
    "        else:\n",
    "            logging.warning(\"Failed to fetch verified crypto list from CoinGecko or Coinbase.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching crypto list: {e}\")\n",
    "    return set(), set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Purpose**: Scrape/find trending cryptocurrencies on Reddit using verified lists.  \n",
    "\n",
    "**Key Features**:  \n",
    "- **Auth**: Connects to Reddit via PRAW using env variables.  \n",
    "- **Trend Analysis**: Identifies most-mentioned crypto (excl. BTC/ETH) in top weekly posts.  \n",
    "- **Post Fetching**: Retrieves posts for a specific crypto keyword with metadata.  \n",
    "- **Validation**: Uses pre-verified crypto symbols/names from CoinGecko/Coinbase.  \n",
    "\n",
    "**Limitations**:  \n",
    "- `valid_crypto_names` may not work reliably (symbol vs. name mismatch).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedditScraper:\n",
    "    def __init__(self):\n",
    "        self.reddit = praw.Reddit(\n",
    "            client_id=os.getenv('REDDIT_CLIENT_ID'),\n",
    "            client_secret=os.getenv('REDDIT_CLIENT_SECRET'),\n",
    "            user_agent=os.getenv('REDDIT_USER_AGENT')\n",
    "        )\n",
    "        self.valid_cryptos, self.valid_crypto_names = get_verified_crypto_list()\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Extract words from text, ensuring they are clean and meaningful.\"\"\"\n",
    "        return re.findall(r'\\b[a-zA-Z0-9-]+\\b', text.lower())\n",
    "\n",
    "    def get_top_trending_coin(self, subreddit='cryptocurrency', limit=100):\n",
    "        \"\"\"Find the most mentioned cryptocurrency in Reddit posts, ensuring it is verified by CoinGecko and Coinbase.\"\"\"\n",
    "        try:\n",
    "            posts = self.reddit.subreddit(subreddit).top(time_filter='week', limit=limit)\n",
    "            keyword_count = Counter()\n",
    "\n",
    "            for post in posts:\n",
    "                words = self.tokenize(post.title)\n",
    "                for word in words:\n",
    "                    if word in self.valid_cryptos or word in self.valid_crypto_names:\n",
    "                        keyword_count[word] += 1\n",
    "\n",
    "            for coin, _ in keyword_count.most_common():\n",
    "                if coin.lower() == \"trump\":\n",
    "                    continue\n",
    "                if coin in self.valid_cryptos or coin in self.valid_crypto_names:\n",
    "                    logging.info(f\"Top trending verified cryptocurrency (excluding BTC & ETH): {coin}\")\n",
    "                    return coin\n",
    "            \n",
    "            logging.warning(\"No trending cryptocurrency found.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching trending cryptocurrency: {e}\")\n",
    "        return None\n",
    "\n",
    "    def get_posts(self, keyword, subreddit='cryptocurrency', limit=50):\n",
    "        \"\"\"Retrieve posts for a given cryptocurrency keyword.\"\"\"\n",
    "        try:\n",
    "            posts = self.reddit.subreddit(subreddit).search(query=keyword, limit=limit, params={'sort': 'new'})\n",
    "            results = []\n",
    "            \n",
    "            exclusion_terms = [\n",
    "                \"president\", \"donates\", \"meet\", \"policy\", \"election\", \"news\",\n",
    "                \"Understanding\", \"administration\", \"donated\", \"campaign\", \"Tariff\",\n",
    "                \"congress\", \"senate\", \"tax\", \"announcement\", \"Chairman\", \"pardon\", \"interview\", \n",
    "                \"lawsuit\", \"motion\", \"White House\", \"says\", \"shilling\"\n",
    "            ]\n",
    "            \n",
    "            for post in posts:\n",
    "                title = post.title.lower()\n",
    "                if keyword.lower() == \"trump\" or any(term in title for term in exclusion_terms):\n",
    "                    continue  # Skip non-crypto Trump mentions\n",
    "\n",
    "                if \"trump coin\" in title or \"trumpcoin\" in title:\n",
    "                    continue\n",
    "                \n",
    "                results.append({\n",
    "                    'keyword': keyword,\n",
    "                    'title': post.title,\n",
    "                    'content': post.selftext,\n",
    "                    'score': post.score,\n",
    "                    'url': post.url,\n",
    "                    'created_at': datetime.fromtimestamp(post.created_utc),\n",
    "                })\n",
    "\n",
    "            logging.info(f\"Found {len(results)} posts for {keyword}\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error getting posts: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataManager`\n",
    "\n",
    "**Handles data cleanup/storage**:  \n",
    "- **Clean**: Strips URLs/special chars, enforces lowercase.  \n",
    "- **Save**: Exports cleaned Reddit posts to dated CSV (e.g., `sol_clean_2024-05-20.csv`).  \n",
    "- Auto-creates folders; logs empty data warnings.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    @staticmethod\n",
    "    def clean_text(text):\n",
    "        \"\"\"Text cleaning pipeline.\"\"\"\n",
    "        if not text or text.strip() == '':\n",
    "            return 'no_content'\n",
    "        text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
    "        return text.lower().strip() or 'no_content'\n",
    "\n",
    "    @staticmethod\n",
    "    def save_data(posts, keyword):\n",
    "        \"\"\"Save post data to a CSV file.\"\"\"\n",
    "        if not posts:\n",
    "            logging.warning(f\"No data to save for {keyword}.\")\n",
    "            return\n",
    "\n",
    "        df = pd.DataFrame(posts)\n",
    "        df['content'] = df['content'].apply(DataManager.clean_text)\n",
    "        \n",
    "        save_dir = \"cleaned_data\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        filename = f\"{save_dir}/{keyword}_clean_{datetime.now().strftime('%Y-%m-%d')}.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "        logging.info(f\"Saved cleaned data to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Execution Flow  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 12:42:15,560 - Loaded 314 verified cryptocurrencies from CoinGecko and Coinbase.\n",
      "2025-02-11 12:42:17,302 - Top trending verified cryptocurrency (excluding BTC & ETH): xrp\n",
      "2025-02-11 12:42:18,371 - Found 41 posts for xrp\n",
      "2025-02-11 12:42:18,374 - Saved cleaned data to cleaned_data/xrp_clean_2025-02-11.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = RedditScraper()\n",
    "    trending_coin = scraper.get_top_trending_coin()\n",
    "\n",
    "    if trending_coin:\n",
    "        posts = scraper.get_posts(trending_coin, limit=50)\n",
    "        DataManager.save_data(posts, trending_coin)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
